# CacheOverloadTree
Cache服务过载问题研究


<pre>
过载：
      外部请求对系统的访问量突然激增，造成请求堆积，服务不可用，最终导致系统崩溃。
</pre>

![](https://i.imgur.com/rGEtRec.png)

<pre>
      A系统：60台机器组成
      B系统：6台机器组成

      之所以6台机器能抗住60台机器的访问，是因为A系统并不是每次都访问B，而是首先请求Cache，
   只有Cache的相应数据失效时才会请求B。

   存在的问题：
      如果Cache发生问题，全部的流量将流向依赖方B，造成流量激增，从而引发B系统的过载。

   造成服务过载的原因至少有下面三种：
      1）B系统的前置代理发生故障或者其他原因造成B系统不可用，等B系统恢复正常，其流量将远远
         超过正常值。
      2）Cache系统故障，A系统流量全部流入B系统
      3）Cache故障恢复，Cache为空，Cache命中率为0，相当于Cache被击穿，流量全部流入B
</pre>

<pre>
服务过载的预防
   Client端： A系统
   Server端： B系统

   Client端方案：
       合理使用Cache应对B系统宕机
           1）基于超时的简单stupid模式
           2）基于超时的常规模式
           3）基于刷新的简单stupid模式
           5）基于刷新的常规模式
           6）基于刷新的续费模式

       应对分布式Cache宕机
           可选的方案
               1）A系统的当前线程不请求B系统，而是打开一个日志并设置一个默认值。
                  B系统利用率为0.
               2）A系统的当前线程按照一定概率决定是否访问B系统
                  保守的设置值
               3）A系统的当前线程检查B系统运行情况，如果良好则请求B系统。
                  更为智能的方案，如果B系统运行良好，当前线程请求；如果运行过载，则不请求。
                  这样A系统将让B系统处于一种宕机与不宕机之间，最大限度挖掘B系统性能。这种方案要求
                  B系统提供一个性能评估接口返回YES,NO，这个接口将被频繁调用，必须高效。

               综合考虑，方案2比较靠谱，如果选择方案3，建议由专门团队负责研究并提供统一的性能实时
               评估方案和工具。

       应对分布式Cache宕机后的恢复
               如果Key的取值空间大于B系统的流量上限，服务过载问题依然在所难免。
               对于Cache宕机的方案，A系统无能为力，只能寄希望于B系统的方案了。
</pre>

<pre>
服务过载的Server端方案

      相对于Client端需要应对各种复杂问题。
      
      1：流量控制
         B系统实时监控当前流量，如果超过预设的值或者系统承受能力，则直接拒绝掉一部分请求，以实现对系统
      的保护。

      流量控制根据基于的数据不同，可分为两种：
          1：基于流量阈值的流控：流量阈值是每个主机的流量上限，流量超过流量阈值主机将进入不稳定状态，
             阈值提前设定，如果主机当前流量超过阈值，则拒绝掉一部分流量，使得实际被处理的流量始终地域
             阈值。
          2：基于主机状态的流控：每个接收每个请求之前先判断当前主机状态，如果主机状况不佳，则拒绝当前
             请求。

      基于阈值的流控实现很简单，但是最大的问题是需要提前设置阈值，而且随着业务逻辑越来越复杂，接口越来
      越多，主机的服务能力实际上应该是下降的，这样就需要不断下调阈值，增加维护成本，而且忘记调整阈值，服务器后果很严重。

      流量控制基于实现位置的不同，又可以分为两种：
          1）反向代理实现流控：在反向代理如Nginx上基于各种策略进行流量控制，这种一般针对HTTP
          2）借助服务治理系统


      2：服务降级
      3：动态扩容
      5：崩溃恢复
</pre>